## 图像分割的研究现状概览

研究主要集中在应用监督学习分割图像，对于半监督和无监督的分割研究较少。

根据 Stanford CS231n（[课件](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf), [视频](https://www.youtube.com/watch?v=6wcs6szJWMY)）的分类，将图像分割问题分成4类：

单物体图像

- 语义分割：像素级别分类
- 分类+定位：根据图像分类然后框定位置

多物体图像

- 对象检测：图像中多物体检测并画框
- 物体检测：检测出物体轮廓+位置框定+分类标签

基本上现在的分割思路就是在提取特征前（或后）在目标区域实施类别分类器实现分类和线性回归实现定位。主要部分：

- [ ] 目标区域选定
- [x] 分类器
- [ ] 定位

主流研究基本上都选择基础的已有图像神经网络（e.g. VGG16，ResNet-101， Inception v1-v3， ResNet，MobileNet）来进行分类工作，主要研究的技术问题存在目标区域选定和定位问题。

**区域选定和定位问题**

`R-CNN`

最早的R-CNN采用了Selective Search的方式提取目标区域（proposal），然后将目标区域分别输入AlexNet分类器+SVM确定分类，和linear regression模型中确定位置（x, y, w, h)，Loss function 为第一个分类器的softmax loss 和第二个回归的L2 Loss 的和来训练。

模型实现了分类和定位功能，准确率也有了很大的提升。但Multi-scale的方式选取目标区域，cnn要处理大量数据，速度慢。

`Fast-R-CNN`

在CNN上用RoI POOL的方式改进了，同时将分类器和回归模型合并到一起，速度有所增快。

但因为将regression也纳入网络中，downsampling的时候图像像素压缩，upsampling时的定位信息会有下降，目前解决办法主要有：

- Max Unpooling， covolutional前技术kernel内最大值的位置，dc的时候将值还原到该位置。
- transpose convolution


`Faster-R-CNN`

在`Fast-R-CNN`上分类器最前面添加一个全连接层，其提取出的特征同时为分类、定位和选取ROI使用，也就是利用CNN来判定是不是目标区域，对物体的比例有一定的学习能力，例如针对车的分类判别，只考虑在一定比例的方块内提取特征，大大减少了目标区域的数量。训练和运行速度有很大的提升。

依然有如何upsampling的问题。

`Mask-R-CNN`

Facebook最新的instance detection，效果惊人，在`faster-r-cnn` 的前端再加入一个全连接层，记录像素信息，实现语义分割。改进了ROI->ROIAligne 确保了像素精度

其他模型SSD，运行速度快，准确率有点低。

DeepLabv3，google的予以分割模型，目前在MSCOCO竞赛中保持第一，接近90%准确率。

DenseCap Object Detection+Captioning, Feifei Li的论文和之前看到text2Image GAN 方向类似。对无人车等应用很现实，后续跟进。

CRF conditional random field (CRF) DeepLab 采用的选取目标点技术。

---

后续计划：

阅读当前主流模型的论文，考虑选择适合我们的运行代码。

基础网络采用：VGG16，ResNet-101， Inception v1-v3， ResNet，MobileNet

主流模型：faster-R-cnn ssd deeplabv3 mask-cnn densecap crf

数据选择 mscoco，理由：

1. 该数据集种类丰富，数量多，是几大模型的训练用集
2. 数据集有在线测试平台，可以供我们进行测验

研究探索：

现有数据主要输入的是图片，难以解决目标区域选择的问题，如果能加入深度信息，重新定义选取算法，将会对准确率和精读有很大提高。











