





Learning Actionable Representations from Visual Observations  https://sites.google.com/view/actionablerepresentations

In this work we explore a new approach for robots to teach themselves about the world simply by observing it. In particular we investigate the effectiveness of learning task-agnostic representations for continuous control tasks. We extend Time-Contrastive Networks (TCN)





PVEs: Position-Velocity Encoders for Unsupervised Learning of Structured State Representations






-----------------------------------------------------------
https://arxiv.org/pdf/1802.04181.pdf
State Representation Learning for Control: An Overview

表格不错



------------------------

UPN  https://arxiv.org/pdf/1804.00645.pdf




SE3-Pose-Nets: Structured Deep Dynamics Models for Visuomotor Planning and Control



