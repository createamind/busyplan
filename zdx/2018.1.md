
now 1 数据检查 2 filter drfl like seqgan 交大作者。 3 视频单独的renset训练。。

wgan + cyclegan

强化学习的动作网络。



预训练unet or resnet 然后取encoder。

2 速度和动作的预测是从endoer中间值还是从预测的最终视频呢？ 中间encoder值处理到低维度 fcn  or drfl ，低纬度后再rnn或CNN来 生成序列
如果从encoder需要resnet结构？unet不合适？ 如果是学习的最终视频那么unet结构也可以使用来训练生成视频，

视频生成：unet，resnet； 中间结果的Encoder+fcn；

3 未来的速度取决于当前场景+当前动作= 下一步的速度和下一步的场景 动作condtion的视频生成 价值很大，验证成功很有用，人的很多决策动作认知都是基于condition，不同的动作产生不同的结果，就是 vid+action+pred-vid ; 视频+动作+生成的视频 3元判断 vid+action2vid
4 强化学习找到视频encoder的某几个filter跟速度预测最相关，这几个filter送入rnn或cnn去预测速度。
5 改造unet可以输出中间encoder值，unet可以多个目标输出，多分支多目标




0：直接rnn、cnn视频学习序列 先监督再对抗。

2 pre-train ： 只训练序列功能无视频生成，预训练序列；2.1 序列和视频生成功能都有，但是开始只训练视频生成功能，等视频生成效果不错了再训练序列生成，
现在从视频b学习seqb，但是视频一直学习的还是A，所以应该学习seqA，或直接先学习seqA，或fix weight train 先训练视频，再训练seq

3 直接unet pretrai video，及video生成效果好了，再生成序列，发现视频生成开始是生成A自己的视频，然后才学习要预测的B的视频。所以可以先进行视频的生成训练，然后进行序列的生成。



G改进：
1.2 视频学习早期还是学习的inputA，所以序列预测增加一个一共两个序列学习，即学习序列seqA，学习序列seqB，看看再训练早期和后期两个序列分别的学习效果！ 实现前沟通确认。

1.2.1 序列学习可以从rnn改为cnn，因为我们的速度动作角度都是连续的，可以增加cnn的序列学习模块。cnn 的seq G


D改进
2  vid+action+pred-vid ;

2.1 vid+pred-action+vid ;

2.2 vid+reward+pred-action+vid ; vid+reward+action+pred-vid vid+reward+pred-action+pred-vid



18.1.10: 
exp: 数据目录随机，预测难度也加大了。预测也跟随波动。     ！！一个场景一个场景的训练。数据也连续不随机。

?  1 cnn 后fcn 再进rnn 预测动作??2 先监督训练一段时间， 3 seqgan 哪一行是mc search？ 4 哪一行是强化学习策略梯度相关代码  
5  capvis实现了左右走的视频 6 tcn time contrast network
7 condtions label 是如何加的    8 视频加动作生成新视频  9   类似8   real fake ——  vid acton vid  10 gps缩略地图和真实地图的映射 就是pix2pix 能学习的。
11 各种condtion gan 如何conditon的  gan集合资料。



