Apollo 框架调研

1.为了快速在试验车上搭建运行环境，测试开发自己的感知算法，需要调研Apollo目前已开源的功能。

定位，感知，决策，控制各个模块实现的算法实现，数据流，各模块的输入输出。

重点在功能的完整性上，其次在于感知模块和决策控制模块的接口，即决策模块需要怎样的感知信息。
最后是更换感知模块的难易程度。

### 模块的实现及接口
- 1.定位

定位模块基于RTKGPS和IMU定位，输入为RTKGPS和IMU的原始数据，输出为LocalizationEstimate，包括对自身位置方向速度加速度的估计。

高精度定位
Baidu ego localization system
结合GPS，高精地图，图像特征匹配的高精度定位，但是运行的硬件环境是 NVIDIA Drive PX2 (PDK 4.1.4.0).


- 2.感知

障碍物检测pipeline由四个子模块组成，HDMap Region of Interest (ROI) Filter，Convolutional Neural Networks (CNN) Segmentation，MinBox Builder，HM Object Tracker。

输入数据为 3D point cloud data 和high-resolution (HD) map，以及必要的坐标变换和标定参数。

输出为：检测，分割，跟踪 高精地图中定义的障碍物，以及障碍物的运动位置，方向，速度，加速度等运动状态。 

- 3.预测

预测障碍物可能的运动轨迹的概率，是沿着某一轨迹运动还是在一区域内运动。

输入为感知模块的检测结果（障碍物及其运动状态），以及定位模块对自身的定位。

输出为障碍物未来的运动轨迹。

- 4.导航

输入为 车辆当前位置和用户的请求目的地。

输出为 导航信息。

5.Canbus

输入为 控制指令

输出为车身运动状态。

6.规划

给定上述所有定位，车身运动状态，地图，导航路径，障碍物感知、跟踪、预测，规划模块可以计算出安全且舒适的运动轨迹并发送控制指令到控制器去执行。
